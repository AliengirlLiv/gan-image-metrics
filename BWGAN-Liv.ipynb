{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff2dba93090>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "global vec0\n",
    "global vec1\n",
    "global ve2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     3,
     20,
     25
    ]
   },
   "outputs": [],
   "source": [
    "def upsample(x):\n",
    "    return nn.functional.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "def downsample(x):\n",
    "    return nn.functional.interpolate(x, scale_factor=0.5, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "def conv_layer(in_filters, out_filters=32, kernel_size=3, he_init=True):\n",
    "    same_padding = (kernel_size-1)//2\n",
    "    conv = nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, padding=same_padding)\n",
    "    \n",
    "    if he_init:\n",
    "        he_init_constant = math.sqrt(6 / (in_filters * kernel_size**2))\n",
    "        nn.init.uniform_(conv.weight, -he_init_constant, he_init_constant)\n",
    "    else:\n",
    "        xavier_init_constant = math.sqrt(6 / ((in_filters + out_filters) * kernel_size**2))\n",
    "        nn.init.uniform_(conv.weight, -xavier_init_constant, xavier_init_constant)\n",
    "    nn.init.constant_(conv.bias, 0)\n",
    "    \n",
    "    return conv\n",
    "\n",
    "def bn(channels):\n",
    "    batchnorm = nn.BatchNorm2d(channels, eps=1e-5)\n",
    "    nn.init.constant_(batchnorm.weight, 1)\n",
    "    return batchnorm\n",
    "\n",
    "def linear(in_features, out_features):\n",
    "    linear_layer = nn.Linear(in_features, out_features)\n",
    "    \n",
    "    xavier_init_constant = math.sqrt(6/(in_features+out_features))\n",
    "    nn.init.uniform_(linear_layer.weight, -xavier_init_constant, xavier_init_constant)\n",
    "    nn.init.constant_(linear_layer.bias, 0)\n",
    "    \n",
    "    return linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     55
    ]
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, resample=None, normalize=False, activation=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.in_filters = in_filters\n",
    "        self.out_filters = out_filters\n",
    "        self.resample = resample\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        self.conv1 = conv_layer(in_filters, out_filters)\n",
    "        self.conv2 = conv_layer(out_filters, out_filters)\n",
    "        \n",
    "        if resample:\n",
    "            self.conv3 = conv_layer(in_filters, out_filters, kernel_size=1, he_init=False)\n",
    "        \n",
    "        if normalize:\n",
    "            self.bn1 = bn(in_filters)\n",
    "            self.bn2 = bn(out_filters)\n",
    "            \n",
    "        if activation is not None:\n",
    "            self.activation = activation\n",
    "        else:\n",
    "            self.activation = nn.ReLU()\n",
    "                \n",
    "    def forward(self, x): \n",
    "        orig_input = x\n",
    "   \n",
    "        if self.normalize:\n",
    "            x = self.bn1(x)\n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "        x = self.activation(x)\n",
    "        \n",
    "        print(\"Activated\", x.shape)\n",
    "        print(x[0, :2, :2,:2])\n",
    "        \n",
    "        if self.resample == 'up':\n",
    "            x = upsample(x)\n",
    "            \n",
    "        print(\"Upsampled\", x.shape)\n",
    "        print(x[0, :2, :2,:2])\n",
    "        \n",
    "        global vec2\n",
    "        vec2 = x\n",
    " \n",
    "       \n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        print(\"AFTER conv1\", x.shape)\n",
    "        print(x[0, :2, :2,:2])\n",
    "\n",
    "        \n",
    "#         print(\"Conv weights\")\n",
    "#         print(self.conv1.weight.data[0, :3, :3, :3])\n",
    "#         print(\"------\")\n",
    "#         print(self.conv1.bias.data)\n",
    "        \n",
    "        \n",
    "        global vec0\n",
    "        vec0 = x\n",
    "        \n",
    "        if self.normalize:\n",
    "            x = self.bn2(x)\n",
    "            \n",
    "        print(\"Normalized again\")\n",
    "        print(x[0, :2, :2,:2])\n",
    "        \n",
    "        global vec1\n",
    "        vec1 = x\n",
    "            \n",
    "        x = self.activation(x)\n",
    "        \n",
    "        print(\"Activated again\")\n",
    "        print(x[0, :2, :2,:2])\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        print(\"AFTER conv2\")\n",
    "        print(x[0, :2, :2,:2])\n",
    "        \n",
    "        raise ValueError(\"hi\")\n",
    "        \n",
    "        if self.resample == 'down':\n",
    "            x = downsample(x)\n",
    "            \n",
    "        print(\"AFTER DOWNSAMPLE\")\n",
    "        print(x[0, :2, :2,:2])\n",
    "        \n",
    "        # Shortcut\n",
    "        if self.resample == 'down': \n",
    "            shortcut_x = downsample(self.conv3(orig_input))\n",
    "        elif self.resample == 'up':\n",
    "            shortcut_x = self.conv3(upsample(orig_input))\n",
    "        elif self.resample == None:\n",
    "            shortcut_x = orig_input\n",
    "            \n",
    "        print(\"SHORTCUT\")\n",
    "        print(shortcut_x[0, :2, :2,:2])\n",
    "        \n",
    "        return x + shortcut_x\n",
    "    \n",
    "class SmallResBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, activation=None):\n",
    "        super(SmallResBlock, self).__init__()\n",
    "        self.in_filters = in_filters\n",
    "        self.out_filters = out_filters\n",
    "        \n",
    "        self.conv1 = conv_layer(in_filters, out_filters)\n",
    "        self.conv2 = conv_layer(out_filters, out_filters)\n",
    "        self.conv3 = conv_layer(in_filters, out_filters, kernel_size=1, he_init=False)\n",
    "            \n",
    "        if activation is not None:\n",
    "            self.activation = activation\n",
    "        else:\n",
    "            self.activation = nn.ReLU()\n",
    "                \n",
    "    def forward(self, x): \n",
    "        orig_input = x\n",
    "       \n",
    "        x = self.conv1(x)   \n",
    "        x = downsample(self.conv2(self.activation(x)))\n",
    "\n",
    "        # Shortcut\n",
    "        shortcut_x = self.conv3(downsample(orig_input))\n",
    "        \n",
    "        return x + shortcut_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, num_filters=128, num_blocks=3, start_image_size=4, num_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.num_filters = num_filters\n",
    "        self.start_image_size = start_image_size\n",
    "        \n",
    "        self.first_linear = linear(input_size, num_filters * start_image_size ** 2)\n",
    "        self.resblocks = nn.ModuleList()\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        for _ in range(num_blocks):\n",
    "            self.resblocks.append(\n",
    "                ResBlock(in_filters=self.num_filters, \n",
    "                         out_filters=self.num_filters, \n",
    "                         resample='up', \n",
    "                         normalize=True))\n",
    "            \n",
    "        self.last_layer = conv_layer(num_filters, num_channels)\n",
    "        self.bn = bn(num_filters)\n",
    "        self.manually_initialize()\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        \n",
    "        print(\"Should be all ones\")\n",
    "        print(noise)\n",
    "        print(noise.size())\n",
    "        \n",
    "        x = self.first_linear(noise)\n",
    "        \n",
    "        print(\"Literally just dense\")\n",
    "        \n",
    "#         print(\"A1\")\n",
    "        \n",
    "        print(x)\n",
    "        print(x.size())\n",
    "        \n",
    "#         x = x.view(-1, self.num_filters, self.start_image_size, self.start_image_size)\n",
    "        x = x.view(-1, self.start_image_size, self.start_image_size, self.num_filters)\n",
    "        print(\"first view reshape\", x[0, :3, :3, :3])\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        print(\"second view reshape\", x[0, :3, :3, :3])\n",
    "        \n",
    "        \n",
    "        global dense_output\n",
    "        dense_output = x\n",
    "        \n",
    "        print(\"After Dense\")\n",
    "        print(x.permute(0,2,3,1))\n",
    "        print(x.size())\n",
    "        \n",
    "        for resblock in self.resblocks:\n",
    "            x = resblock(x)\n",
    "#             print(\"B\")\n",
    "#             print(x)\n",
    "#             print(x.size())\n",
    "            \n",
    "        x = self.activation(self.bn(x))\n",
    "        result = self.last_layer(x)\n",
    "        return torch.tanh(result)\n",
    "    \n",
    "    def manually_initialize(self):\n",
    "        print(self.first_linear.weight.data[0,0:3])\n",
    "        self.first_linear.weight.data = torch.tensor(np.load(\"params/generator_dense_kernel:0.npy\")).transpose(0,1).contiguous()\n",
    "        self.first_linear.bias.data = torch.tensor(np.load(\"params/generator_dense_bias:0.npy\")).contiguous()\n",
    "        print(self.first_linear.weight.data[0:3,0])\n",
    "        \n",
    "        self.resblocks[0].bn1.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_gamma:0.npy\")).contiguous()\n",
    "        self.resblocks[0].bn1.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_beta:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[0].bn2.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_1_gamma:0.npy\")).contiguous()\n",
    "        self.resblocks[0].bn2.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_1_beta:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[1].bn1.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_2_gamma:0.npy\")).contiguous()\n",
    "        self.resblocks[1].bn1.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_2_beta:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[1].bn2.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_3_gamma:0.npy\")).contiguous()\n",
    "        self.resblocks[1].bn2.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_3_beta:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[2].bn1.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_4_gamma:0.npy\")).contiguous()\n",
    "        self.resblocks[2].bn1.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_4_beta:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[2].bn2.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_5_gamma:0.npy\")).contiguous()\n",
    "        self.resblocks[2].bn2.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_5_beta:0.npy\")).contiguous()\n",
    "        \n",
    "        self.bn.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_6_gamma:0.npy\")).contiguous()\n",
    "        self.bn.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_6_beta:0.npy\")).contiguous()\n",
    "        \n",
    "        # Insert \"contiguous\" to make conv layers work correctly.  Not strictly necessary when using the gpu,\n",
    "        # but will hopefully help us avoid headaches later\n",
    "        self.resblocks[0].conv1.weight.data = torch.tensor(np.load(\"params/generator_conv2d_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[0].conv1.bias.data = torch.tensor(np.load(\"params/generator_conv2d_bias:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[0].conv2.weight.data = torch.tensor(np.load(\"params/generator_conv2d_1_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[0].conv2.bias.data = torch.tensor(np.load(\"params/generator_conv2d_1_bias:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[0].conv3.weight.data = torch.tensor(np.load(\"params/generator_conv2d_2_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[0].conv3.bias.data = torch.tensor(np.load(\"params/generator_conv2d_2_bias:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[1].conv1.weight.data = torch.tensor(np.load(\"params/generator_conv2d_3_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[1].conv1.bias.data = torch.tensor(np.load(\"params/generator_conv2d_3_bias:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[1].conv2.weight.data = torch.tensor(np.load(\"params/generator_conv2d_4_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[1].conv2.bias.data = torch.tensor(np.load(\"params/generator_conv2d_4_bias:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[1].conv3.weight.data = torch.tensor(np.load(\"params/generator_conv2d_5_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[1].conv3.bias.data = torch.tensor(np.load(\"params/generator_conv2d_5_bias:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[2].conv1.weight.data = torch.tensor(np.load(\"params/generator_conv2d_6_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[2].conv1.bias.data = torch.tensor(np.load(\"params/generator_conv2d_6_bias:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[2].conv2.weight.data = torch.tensor(np.load(\"params/generator_conv2d_7_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[2].conv2.bias.data = torch.tensor(np.load(\"params/generator_conv2d_7_bias:0.npy\")).contiguous()\n",
    "        \n",
    "        self.resblocks[2].conv3.weight.data = torch.tensor(np.load(\"params/generator_conv2d_8_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[2].conv3.bias.data = torch.tensor(np.load(\"params/generator_conv2d_8_bias:0.npy\")).contiguous()\n",
    "        \n",
    "        self.last_layer.weight.data = torch.tensor(np.load(\"params/generator_conv2d_9_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.last_layer.bias.data = torch.tensor(np.load(\"params/generator_conv2d_9_bias:0.npy\")).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLPLayer, self).__init__()\n",
    "        self.block = nn.Sequential(linear(input_size, output_size), nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class VectorDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_blocks):\n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.blocks.append(MLPLayer(input_size, hidden_size))\n",
    "        \n",
    "        for _ in range(num_blocks - 1):\n",
    "            self.blocks.append(hidden_size, hidden_size)\n",
    "        \n",
    "        self.blocks.append(linear(hidden_size, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ImageDiscriminator(nn.Module):\n",
    "    def __init__(self, num_filters=128, num_blocks=4, num_channels=3):\n",
    "        super(ImageDiscriminator, self).__init__()\n",
    "        assert num_blocks >= 2, \"Number of conv layers in the discriminator must be >= 2.\"\n",
    "        \n",
    "        self.resblocks = nn.ModuleList()\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        self.resblocks.append(SmallResBlock(in_filters=num_channels, \n",
    "                                            out_filters=num_filters))\n",
    "        self.resblocks.append(ResBlock(in_filters=num_filters, \n",
    "                                       out_filters=num_filters, \n",
    "                                       resample='down'))\n",
    "        for _ in range(num_blocks - 2):\n",
    "            self.resblocks.append(ResBlock(in_filters=num_filters, \n",
    "                                           out_filters=num_filters))\n",
    "            \n",
    "        self.last_linear = linear(num_filters, 1)\n",
    "        self.manually_initialize()\n",
    "   \n",
    "    def forward(self, x):\n",
    "        for resblock in self.resblocks:\n",
    "            x = resblock(x)\n",
    "            \n",
    "        x = self.activation(x)\n",
    "        x = x.mean(dim=(-1,-2))\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "    \n",
    "    def manually_initialize(self):\n",
    "        print('hi')\n",
    "#         self.last_linear.weight.data = torch.tensor(np.load(\"params/discriminator_dense_kernel:0.npy\")).transpose(0,1)\n",
    "#         self.last_linear.bias.data = torch.tensor(np.load(\"params/discriminator_dense_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[0].conv1.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[0].conv1.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[0].conv2.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_1_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[0].conv2.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_1_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[0].conv3.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_2_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[0].conv3.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_2_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[1].conv1.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_3_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[1].conv1.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_3_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[1].conv2.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_4_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[1].conv2.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_4_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[1].conv3.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_5_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[1].conv3.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_5_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[2].conv1.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_6_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[2].conv1.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_6_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[2].conv2.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_7_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[2].conv2.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_7_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[3].conv1.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_8_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[3].conv1.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_8_bias:0.npy\"))\n",
    "        \n",
    "#         self.resblocks[3].conv2.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_9_kernel:0.npy\")).permute(3,2,1,0)\n",
    "#         self.resblocks[3].conv2.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_9_bias:0.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def identity_embedding(pic):\n",
    "    return pic\n",
    "\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, gamma, noise_size=128, num_filters=128, num_generator_blocks=3, num_discriminator_blocks=4,\n",
    "                 batch_size=64, num_channels=3, discriminator_epsilon=1e-5, banach=True, \n",
    "                 embedding_func=identity_embedding, embedding_size=None, discriminator_hidden_size=None,\n",
    "                 discriminator_type=\"Image\"):  \n",
    "        super(GAN, self).__init__()\n",
    "        self.generator = Generator(noise_size, num_filters=num_filters, num_blocks=num_generator_blocks,\n",
    "                                   start_image_size=4, num_channels=num_channels)\n",
    "        \n",
    "        if discriminator_type == \"Image\":\n",
    "            self.discriminator = ImageDiscriminator(num_filters=num_filters, num_blocks=num_discriminator_blocks, \n",
    "                                                    num_channels=num_channels)\n",
    "        elif discriminator_type == \"Vector\":\n",
    "            self.discriminator = VectorDiscriminator(input_size=embedding_size, \n",
    "                                                     hidden_size=discriminator_hidden_size,\n",
    "                                                     num_blocks=num_discriminator_blocks)\n",
    "        else:\n",
    "            raise ValueError(\"Discriminator type not recognized.\")\n",
    "        self.discriminator_epsilon = discriminator_epsilon\n",
    "        \n",
    "        # Assumption that the dual space is the same as the original space.\n",
    "        self.gamma = gamma\n",
    "        self.lambda_penalty = gamma\n",
    "        \n",
    "        self.banach = banach # Boolean parameter that decides on whether to do a banach/metric space based wgan.\n",
    "        self.embedding_func = embedding_func # The embedding function used.\n",
    "        \n",
    "        self.register_buffer(\"penalty_grad_outputs\", torch.ones(batch_size))\n",
    "        self.register_buffer(\"noise_buffer\", torch.ones((batch_size, noise_size)))\n",
    "        self.register_buffer(\"epsilon_buffer\", torch.ones(batch_size, 1, 1, 1))\n",
    "        \n",
    "    def forward_train_generator(self, noise=None):\n",
    "        generated_image = self.forward_predict_generator(noise)\n",
    "        discriminator_score_generated = self.forward_predict_discriminator(generated_image)\n",
    "        return self.generator_loss(discriminator_score_generated)\n",
    "    \n",
    "    def forward_train_discriminator(self, real_images, noise=None):\n",
    "        generated_images = self.forward_predict_generator(noise)\n",
    "        discriminator_score_generated = self.forward_predict_discriminator(generated_images)\n",
    "        discriminator_score_real = self.forward_predict_discriminator(real_images)\n",
    "        return self.discriminator_loss(discriminator_score_real, discriminator_score_generated, real_images, generated_images)\n",
    "        \n",
    "    def forward_predict_generator(self, noise=None):\n",
    "        if noise is None:\n",
    "            noise = self.generate_noise()\n",
    "        return self.generator(noise)\n",
    "        \n",
    "    def forward_predict_discriminator(self, image):\n",
    "        return self.discriminator(image)\n",
    "    \n",
    "    def generate_noise(self):\n",
    "        return torch.randn_like(self.noise_buffer)\n",
    "    \n",
    "    def generator_loss(self, d_score_generated):\n",
    "#         print(\"Generator loss\", torch.mean(d_generated_train) / self.gamma)\n",
    "        return torch.mean(d_score_generated) / self.gamma #NOTE: Mehdi's version had a negative sign, original was positive\n",
    "    \n",
    "    def stable_norm(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        alpha, _ = (x.abs() + 1e-5).max(1)\n",
    "        \n",
    "        return alpha * (x/alpha.unsqueeze(1)).norm(p=2, dim=1)\n",
    "    \n",
    "    def discriminator_loss(self, d_score_real, d_score_generated, real_images, generated_images):\n",
    "#         print(\"d score generated\", torch.mean(d_score_generated))\n",
    "#         print(\"d score real\", torch.mean(d_score_real))\n",
    "        wasserstein_loss = (torch.mean(d_score_generated) - torch.mean(d_score_real)) / self.gamma\n",
    "#         print(\"wass loss\", wasserstein_loss)\n",
    "        epsilon = self.epsilon_buffer.uniform_(0, 1)\n",
    "        real_fake_mix = epsilon * generated_images + (1 - epsilon) * real_images \n",
    "        d_score_mix = self.discriminator(real_fake_mix).squeeze(1)\n",
    "        \n",
    "        gradients = torch.autograd.grad(d_score_mix, real_fake_mix, grad_outputs=self.penalty_grad_outputs,\n",
    "                                        create_graph=True)[0]\n",
    "        \n",
    "#         print(gradients)\n",
    "        gradient_penalty = torch.mean(self.stable_norm(gradients) / gamma - 1) ** 2\n",
    "        print(\"grad penalty\", float(self.lambda_penalty * gradient_penalty))\n",
    "        d_regularizer_mean = torch.mean(d_score_real ** 2)\n",
    "#         print(\"regularizer mean\", float(self.discriminator_epsilon * d_regularizer_mean))\n",
    "#         \n",
    "        #NOTE: Mehdi's version had the wassestein loss positive, original seems to be negative\n",
    "#         print(\"w loss is\", -float(wasserstein_loss))\n",
    "        d_loss = -wasserstein_loss + self.lambda_penalty * gradient_penalty + self.discriminator_epsilon * d_regularizer_mean\n",
    "#         print(\"Overall d_loss\", d_loss.item())\n",
    "        return d_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# There is one discrepancy in this training code and the bwgan github implementation. That\n",
    "# version uses an exponential moving average of the weights during evaluation.\n",
    "#\n",
    "# One other discrepancy with bwgan is the lack of usage of warm restarts for SGD. That's mentioned in\n",
    "# the paper but I could not see in the implementation.\n",
    "#\n",
    "# The last main discrepancy is related to the model. In the bwgan code gamma is computed each batch. Here\n",
    "# we compute gamma over the dataset instead. The difference should be very minor as gamma's value across batches\n",
    "# is pretty stable. For MNIST gamma appeared to range from 29.8-30.1 from looking at a dozen gamma values.\n",
    "def gan_train(model, dset_loader, optimizers, lr_schedulers, num_updates=1e5,\n",
    "              use_cuda=False, num_discriminator=5):\n",
    "    steps_so_far = 0\n",
    "    curr_epoch = 0\n",
    "    \n",
    "    discriminator_optimizer, generator_optimizer = optimizers\n",
    "    discriminator_lr_scheduler, generator_lr_scheduler = lr_schedulers\n",
    "    \n",
    "    display_generator = False\n",
    "    \n",
    "    while True:\n",
    "        print('Epoch {} - Step {}/{}'.format(curr_epoch, steps_so_far, num_updates))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data, _ in dset_loader:\n",
    "            \n",
    "            print(steps_so_far)\n",
    "            if steps_so_far % 1000 == 0:\n",
    "                print(steps_so_far)\n",
    "            \n",
    "            if steps_so_far >= num_updates:\n",
    "                return model\n",
    "            \n",
    "            if use_cuda:\n",
    "                data = data.cuda()\n",
    "            \n",
    "            loss = model.forward_train_discriminator(data)\n",
    "#             register_hooks(loss)\n",
    "            \n",
    "            if steps_so_far % 100 == 4:\n",
    "                print(\"Discriminator Loss: \", loss.item())\n",
    "                display_generator = True\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            discriminator_optimizer.step()\n",
    "            # zero the parameter gradients\n",
    "            discriminator_optimizer.zero_grad()\n",
    "                \n",
    "                \n",
    "            if steps_so_far % num_discriminator == num_discriminator-1:\n",
    "                loss = model.forward_train_generator()\n",
    "                loss.backward()\n",
    "                generator_optimizer.step()\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                generator_optimizer.zero_grad()\n",
    "\n",
    "                discriminator_lr_scheduler.step()\n",
    "                generator_lr_scheduler.step()\n",
    "                if display_generator:\n",
    "                    print(\"Generator Loss: \", loss.item())\n",
    "                    display_generator = False\n",
    "                    \n",
    "                    \n",
    "            if steps_so_far % 500 == 0:\n",
    "                generated_images = model.forward_predict_generator()\n",
    "                first_image = generated_images[0, 0].cpu().detach().numpy()\n",
    "                min_val = float(np.amin(first_image))\n",
    "                max_val = float(np.amax(first_image))\n",
    "                plt.title(\"Generated image, range {} to {}\".format(round(min_val, 3), round(max_val, 3)))\n",
    "                plt.imshow(first_image)\n",
    "                plt.show()\n",
    "            \n",
    "            steps_so_far += 1\n",
    "        \n",
    "        curr_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_gamma(dset_loader):\n",
    "    num_images = len(dset_loader.dataset)\n",
    "    gamma = 0.0\n",
    "    \n",
    "    for data, _ in dset_loader:\n",
    "        batch_size = data.size()[0]\n",
    "        gamma += data.cuda().view(batch_size, -1).norm(2, dim=1).sum().item() / num_images\n",
    "    \n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_graph(root, callback):\n",
    "    queue = [root]\n",
    "    seen = set()\n",
    "    while queue:\n",
    "        fn = queue.pop()\n",
    "        if fn in seen:\n",
    "            continue\n",
    "        seen.add(fn)\n",
    "        for next_fn, _ in fn.next_functions:\n",
    "            if next_fn is not None:\n",
    "                queue.append(next_fn)\n",
    "        callback(fn)\n",
    "\n",
    "def register_hooks(var):\n",
    "    def is_bad_grad(grad_output):\n",
    "        if grad_output is None:\n",
    "            return False\n",
    "        \n",
    "        grad_output = grad_output.data\n",
    "        return grad_output.ne(grad_output).any() or grad_output.gt(1e4).any()\n",
    "    \n",
    "    def hook_cb(fn):\n",
    "        def register_grad(grad_input, grad_output):\n",
    "            for grad in grad_output:\n",
    "                if is_bad_grad(grad):\n",
    "                    print(fn)\n",
    "#                     raise ValueError(\"Hi\")\n",
    "        fn.register_hook(register_grad)\n",
    "    iter_graph(var.grad_fn, hook_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_size = 128\n",
    "batch_size = 1\n",
    "use_cuda = True\n",
    "base_lr = 2e-4\n",
    "num_updates = int(1e2)\n",
    "num_discriminator = 5\n",
    "num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(name, train=True):\n",
    "    assert name in [\"mnist\", \"cifar\", \"celeba\"]\n",
    "    transform = transforms.Compose([transforms.Resize(32),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "    if name == \"mnist\":\n",
    "        return datasets.MNIST(\"mnist\", train=train, download=True, transform=transform)\n",
    "    if name == \"cifar\":\n",
    "        return datasets.CIFAR10(\"cifar\", train=train, transform=transform, download=True)\n",
    "    if name == \"celeba\":\n",
    "        if train == True:\n",
    "            dset_str = \"train\"\n",
    "        else:\n",
    "            dset_str = \"test\"\n",
    "        with open(\"celeba_64_bgr_-1_to_1_%s.pkl\" % dset_str, \"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = get_data(\"cifar\")\n",
    "# train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "#                                    num_workers=4, pin_memory=True, drop_last=True)\n",
    "gamma = 27 #compute_gamma(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0329, -0.0379, -0.0009])\n",
      "tensor([-0.0185,  0.0220,  0.0163])\n",
      "hi\n",
      "Should be all ones\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.]])\n",
      "torch.Size([1, 128])\n",
      "Literally just dense\n",
      "tensor([[-0.2824,  0.1309, -0.1149,  ..., -0.3147, -0.2160, -0.0382]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "torch.Size([1, 2048])\n",
      "first view reshape tensor([[[-0.2824,  0.1309, -0.1149],\n",
      "         [ 0.1462,  0.3888, -0.3026],\n",
      "         [ 0.3701,  0.1530,  0.4670]],\n",
      "\n",
      "        [[-0.4724, -0.7412, -0.2681],\n",
      "         [ 1.0154,  0.1076, -0.5858],\n",
      "         [ 0.3558, -0.1052,  0.4186]],\n",
      "\n",
      "        [[ 0.2085, -0.8711,  0.7487],\n",
      "         [-0.3292, -0.2729,  0.5168],\n",
      "         [-0.7029,  0.5389,  0.2108]]], grad_fn=<SliceBackward>)\n",
      "second view reshape tensor([[[-0.2824,  0.1462,  0.3701],\n",
      "         [-0.4724,  1.0154,  0.3558],\n",
      "         [ 0.2085, -0.3292, -0.7029]],\n",
      "\n",
      "        [[ 0.1309,  0.3888,  0.1530],\n",
      "         [-0.7412,  0.1076, -0.1052],\n",
      "         [-0.8711, -0.2729,  0.5389]],\n",
      "\n",
      "        [[-0.1149, -0.3026,  0.4670],\n",
      "         [-0.2681, -0.5858,  0.4186],\n",
      "         [ 0.7487,  0.5168,  0.2108]]], grad_fn=<SliceBackward>)\n",
      "After Dense\n",
      "tensor([[[[-0.2824,  0.1309, -0.1149,  ..., -0.2591,  0.2442, -0.5092],\n",
      "          [ 0.1462,  0.3888, -0.3026,  ..., -0.6472, -0.5298,  0.4293],\n",
      "          [ 0.3701,  0.1530,  0.4670,  ..., -0.1710, -0.1390,  0.4779],\n",
      "          [ 0.0865,  0.0982,  0.2719,  ...,  0.1653,  0.3191,  0.4857]],\n",
      "\n",
      "         [[-0.4724, -0.7412, -0.2681,  ..., -0.0080,  0.0072, -0.3667],\n",
      "          [ 1.0154,  0.1076, -0.5858,  ..., -0.3616, -0.4806, -0.4388],\n",
      "          [ 0.3558, -0.1052,  0.4186,  ...,  0.1252,  0.2889, -0.0345],\n",
      "          [ 0.2816,  0.5723,  0.2435,  ..., -0.1841, -0.0644,  0.7267]],\n",
      "\n",
      "         [[ 0.2085, -0.8711,  0.7487,  ..., -0.0943, -0.1879, -0.3436],\n",
      "          [-0.3292, -0.2729,  0.5168,  ...,  0.0084, -0.0992,  0.1430],\n",
      "          [-0.7029,  0.5389,  0.2108,  ...,  0.6587, -0.3255,  0.1979],\n",
      "          [-0.1156, -0.2623, -0.4988,  ..., -0.3909, -0.4289, -0.5743]],\n",
      "\n",
      "         [[ 0.3004,  0.7182,  0.6724,  ..., -0.4278,  0.6043,  0.0655],\n",
      "          [-0.1277, -0.1441,  0.1573,  ..., -0.5108,  0.3556,  0.0182],\n",
      "          [ 0.3453,  0.3483,  0.2061,  ..., -0.0981, -0.3341,  0.2272],\n",
      "          [-0.2085, -0.0174,  0.3971,  ..., -0.3147, -0.2160, -0.0382]]]],\n",
      "       grad_fn=<PermuteBackward>)\n",
      "torch.Size([1, 128, 4, 4])\n",
      "Activated torch.Size([1, 128, 4, 4])\n",
      "tensor([[[0.0000, 0.2282],\n",
      "         [0.0000, 2.3898]],\n",
      "\n",
      "        [[0.2123, 0.8153],\n",
      "         [0.0000, 0.1578]]], grad_fn=<SliceBackward>)\n",
      "Upsampled torch.Size([1, 128, 8, 8])\n",
      "tensor([[[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2123, 0.2123],\n",
      "         [0.2123, 0.2123]]], grad_fn=<SliceBackward>)\n",
      "AFTER conv1 torch.Size([1, 128, 8, 8])\n",
      "tensor([[[ 0.6503, -0.2126],\n",
      "         [-0.0727, -0.4083]],\n",
      "\n",
      "        [[-0.6203, -1.3469],\n",
      "         [ 0.8679, -0.4857]]], grad_fn=<SliceBackward>)\n",
      "Normalized again\n",
      "tensor([[[ 1.2781,  0.1953],\n",
      "         [ 0.3709, -0.0503]],\n",
      "\n",
      "        [[-1.3228, -2.3298],\n",
      "         [ 0.7398, -1.1363]]], grad_fn=<SliceBackward>)\n",
      "Activated again\n",
      "tensor([[[1.2781, 0.1953],\n",
      "         [0.3709, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.7398, 0.0000]]], grad_fn=<SliceBackward>)\n",
      "AFTER conv2\n",
      "tensor([[[-0.1161, -0.1942],\n",
      "         [-0.2515,  0.2656]],\n",
      "\n",
      "        [[ 0.4794,  0.0402],\n",
      "         [ 1.2969,  0.0914]]], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "hi",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-ffc017bb423c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_predict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# output2 = model.forward_predict_discriminator(output1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-29545cfac0f2>\u001b[0m in \u001b[0;36mforward_predict_generator\u001b[0;34m(self, noise)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_predict_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1f48286f3c56>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, noise)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mresblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;31m#             print(\"B\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#             print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ddbf356e374d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'down'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: hi"
     ]
    }
   ],
   "source": [
    "model = GAN(gamma=gamma, noise_size=noise_size, batch_size=batch_size, num_channels=num_channels)\n",
    "model.train()\n",
    "y = torch.ones(1,128)\n",
    "output1 = model.forward_predict_generator(y)\n",
    "# output2 = model.forward_predict_discriminator(output1)\n",
    "\n",
    "print(output1.size())\n",
    "print(output1.permute(0,2,3,1)[0])\n",
    "\n",
    "# print(output2)\n",
    "\n",
    "# if use_cuda:\n",
    "#     model = model.cuda()\n",
    "#     model.discriminator = nn.DataParallel(model.discriminator)\n",
    "#     model.generator = nn.DataParallel(model.generator)\n",
    "\n",
    "# discriminator_optimizer = optim.Adam(model.discriminator.parameters(), betas=(0, 0.9), lr=base_lr)\n",
    "# generator_optimizer = optim.Adam(model.generator.parameters(), betas=(0, 0.9), lr=base_lr)\n",
    "# discriminator_lr_scheduler = optim.lr_scheduler.LambdaLR(discriminator_optimizer, lambda step: max(0, (1 - step/num_updates)))\n",
    "# generator_lr_scheduler = optim.lr_scheduler.LambdaLR(generator_optimizer, lambda step: max(0, (1 - step/num_updates)))\n",
    "# optimizers = discriminator_optimizer, generator_optimizer\n",
    "# lr_schedulers = discriminator_lr_scheduler, generator_lr_scheduler\n",
    "\n",
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "# model.train()\n",
    "# model = gan_train(model, train_dataloader, optimizers, lr_schedulers, num_updates=num_updates, \n",
    "#                   use_cuda=use_cuda, num_discriminator=num_discriminator)\n",
    "# print(time.time() - start_time)\n",
    "# kangaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 8, 128]) (1, 8, 8, 128)\n",
      "False\n",
      "[[[0.         0.21231355 0.         0.        ]\n",
      "  [0.         0.21231355 0.         0.        ]\n",
      "  [0.22819537 0.81528354 0.         0.        ]\n",
      "  [0.22819537 0.81528354 0.         0.        ]]\n",
      "\n",
      " [[0.         0.21231355 0.         0.        ]\n",
      "  [0.         0.21231355 0.         0.        ]\n",
      "  [0.22819537 0.81528354 0.         0.        ]\n",
      "  [0.22819537 0.81528354 0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.5992161 ]\n",
      "  [0.         0.         0.         0.5992161 ]\n",
      "  [2.3898323  0.15784769 0.         0.        ]\n",
      "  [2.3898323  0.15784769 0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         0.5992161 ]\n",
      "  [0.         0.         0.         0.5992161 ]\n",
      "  [2.3898323  0.15784769 0.         0.        ]\n",
      "  [2.3898323  0.15784769 0.         0.        ]]]\n",
      "tensor([[[0.0000, 0.2123, 0.0000, 0.0000],\n",
      "         [0.0000, 0.2123, 0.0000, 0.0000],\n",
      "         [0.2282, 0.8153, 0.0000, 0.0000],\n",
      "         [0.2282, 0.8153, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.2123, 0.0000, 0.0000],\n",
      "         [0.0000, 0.2123, 0.0000, 0.0000],\n",
      "         [0.2282, 0.8153, 0.0000, 0.0000],\n",
      "         [0.2282, 0.8153, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.5992],\n",
      "         [0.0000, 0.0000, 0.0000, 0.5992],\n",
      "         [2.3898, 0.1578, 0.0000, 0.0000],\n",
      "         [2.3898, 0.1578, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.5992],\n",
      "         [0.0000, 0.0000, 0.0000, 0.5992],\n",
      "         [2.3898, 0.1578, 0.0000, 0.0000],\n",
      "         [2.3898, 0.1578, 0.0000, 0.0000]]], grad_fn=<SliceBackward>)\n",
      "Are they basically the same? -0.0002708314\n",
      "============================================================\n",
      "torch.Size([1, 8, 8, 128])\n",
      "(1, 8, 8, 128)\n",
      "False\n",
      "[[[ 0.65031743 -0.6203244  -0.49183062  0.5059358 ]\n",
      "  [-0.46407175 -0.29227483  0.26989132  0.51021767]\n",
      "  [-1.0963885  -0.18039542 -0.03942381  0.01116517]\n",
      "  [-0.01355213 -1.1024314   0.908952   -0.8055963 ]]\n",
      "\n",
      " [[ 0.3085447  -0.1323849  -0.9388524  -0.35478938]\n",
      "  [-0.46749058 -0.29016238 -0.33011514  0.68282115]\n",
      "  [-0.6955725   1.0970619  -0.3160039   0.3884605 ]\n",
      "  [-0.41365647  0.04078609 -0.12548155 -1.4246851 ]]\n",
      "\n",
      " [[-0.10411834  0.51131546 -1.0829896  -0.43522996]\n",
      "  [-0.33119974  0.138413   -0.40443015  0.47714132]\n",
      "  [-0.15165797  0.76694345 -0.11138994  1.58388   ]\n",
      "  [-0.8337002   0.34788638 -0.9980562   0.067044  ]]\n",
      "\n",
      " [[ 0.23109788  1.4915797  -0.7278441   0.02084608]\n",
      "  [ 0.857631    1.3171991  -0.6583799   0.8164354 ]\n",
      "  [ 0.1107682   0.47141552 -0.12110358  1.7047334 ]\n",
      "  [-0.31242093  2.121894   -1.4275885   1.3573148 ]]]\n",
      "tensor([[[ 0.6503, -0.6203, -0.4918,  0.5059],\n",
      "         [-0.2126, -1.3469, -0.3349, -0.1479],\n",
      "         [-0.5073, -1.2216, -0.0409, -0.7569],\n",
      "         [-0.0644,  0.1205, -0.1825, -0.1985]],\n",
      "\n",
      "        [[-0.0727,  0.8679, -0.2711,  1.0268],\n",
      "         [-0.4083, -0.4857,  0.1271,  1.2970],\n",
      "         [-0.9630, -0.7848,  0.5900,  0.1173],\n",
      "         [-1.1073, -0.0486,  0.3557, -0.3580]],\n",
      "\n",
      "        [[-0.6932,  1.5525, -1.0815,  0.3328],\n",
      "         [ 0.1294,  2.0132,  0.0781,  0.9088],\n",
      "         [-0.0176,  0.9553,  0.8199,  1.1302],\n",
      "         [-1.1522,  0.4118,  0.5367,  0.0246]],\n",
      "\n",
      "        [[-0.6913, -0.1880, -0.4468, -0.2447],\n",
      "         [-0.3319,  1.5250, -0.8891, -0.1202],\n",
      "         [-0.5228,  1.1797, -1.2116,  0.9437],\n",
      "         [-0.5150,  0.8631, -1.6716,  0.7641]]], grad_fn=<SliceBackward>)\n",
      "----------------------------------------------------------------------\n",
      "0.07031492\n",
      "0.067753114\n"
     ]
    }
   ],
   "source": [
    "py_up = vec2.permute(0,2,3,1).contiguous()\n",
    "tf_up = np.load(\"upsampled.npy\")\n",
    "print(py_up.shape, tf_up.shape)\n",
    "print(np.array_equal(tf_up, py_up.cpu().detach().numpy()))\n",
    "print(tf_up[0,:4,:4,:4])\n",
    "print(py_up[0,:4,:4,:4])\n",
    "print(\"Are they basically the same?\", np.sum(tf_up - py_up.cpu().detach().numpy()))\n",
    "print(\"======\" * 10)\n",
    "\n",
    "py_bn_input = vec0.permute(0,2,3,1).contiguous()\n",
    "tf_bn_input = np.load(\"bn_input.npy\")\n",
    "print(py_bn_input.shape)\n",
    "print(tf_bn_input.shape)\n",
    "print(np.array_equal(tf_bn_input, py_bn_input.cpu().detach().numpy()))\n",
    "print(tf_bn_input[0,:4,:4,:4])\n",
    "print(py_bn_input[0,:4,:4,:4])\n",
    "\n",
    "print(\"--------------\" * 5)\n",
    "print(np.mean(py_bn_input.cpu().detach().numpy()))\n",
    "print(np.mean(tf_bn_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128, 3, 3])\n",
      "tensor([[[[ 0.0063,  0.0668, -0.0036,  ...,  0.0325,  0.0310, -0.0140],\n",
      "          [-0.0357,  0.0247, -0.0519,  ...,  0.0236, -0.0460, -0.0439],\n",
      "          [-0.0586,  0.0667,  0.0048,  ...,  0.0506, -0.0011, -0.0602],\n",
      "          ...,\n",
      "          [ 0.0390,  0.0260,  0.0249,  ..., -0.0318, -0.0659, -0.0619],\n",
      "          [ 0.0586,  0.0379,  0.0611,  ...,  0.0160, -0.0060, -0.0391],\n",
      "          [-0.0629,  0.0580,  0.0303,  ...,  0.0295,  0.0052, -0.0292]],\n",
      "\n",
      "         [[-0.0569,  0.0478,  0.0292,  ..., -0.0126,  0.0547, -0.0509],\n",
      "          [-0.0274, -0.0698, -0.0083,  ...,  0.0274, -0.0480, -0.0671],\n",
      "          [-0.0486,  0.0319, -0.0687,  ...,  0.0449,  0.0442, -0.0662],\n",
      "          ...,\n",
      "          [-0.0378,  0.0239,  0.0275,  ..., -0.0624,  0.0005,  0.0372],\n",
      "          [-0.0452, -0.0290, -0.0406,  ...,  0.0335, -0.0294,  0.0070],\n",
      "          [ 0.0267, -0.0139, -0.0078,  ...,  0.0571, -0.0209,  0.0242]],\n",
      "\n",
      "         [[-0.0061,  0.0247,  0.0241,  ..., -0.0638, -0.0418,  0.0468],\n",
      "          [-0.0720,  0.0430,  0.0403,  ...,  0.0709,  0.0452,  0.0018],\n",
      "          [-0.0204,  0.0063, -0.0305,  ...,  0.0230,  0.0122, -0.0413],\n",
      "          ...,\n",
      "          [-0.0116,  0.0409,  0.0438,  ...,  0.0154, -0.0251, -0.0524],\n",
      "          [ 0.0025, -0.0592,  0.0564,  ...,  0.0707, -0.0461,  0.0192],\n",
      "          [ 0.0688, -0.0021, -0.0160,  ...,  0.0395,  0.0265,  0.0180]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0670,  0.0269,  0.0133,  ...,  0.0563, -0.0188, -0.0567],\n",
      "          [-0.0491,  0.0044,  0.0300,  ...,  0.0484,  0.0203,  0.0123],\n",
      "          [-0.0508, -0.0578, -0.0218,  ...,  0.0631,  0.0235,  0.0651],\n",
      "          ...,\n",
      "          [ 0.0188, -0.0405, -0.0581,  ..., -0.0189, -0.0380,  0.0013],\n",
      "          [-0.0139, -0.0492, -0.0310,  ..., -0.0482,  0.0225, -0.0578],\n",
      "          [-0.0205, -0.0248, -0.0608,  ..., -0.0580,  0.0468, -0.0173]],\n",
      "\n",
      "         [[ 0.0131, -0.0481,  0.0085,  ..., -0.0556,  0.0361,  0.0111],\n",
      "          [-0.0709,  0.0528, -0.0311,  ..., -0.0450, -0.0590, -0.0482],\n",
      "          [ 0.0340,  0.0515, -0.0466,  ..., -0.0201,  0.0245, -0.0539],\n",
      "          ...,\n",
      "          [ 0.0013,  0.0603,  0.0098,  ...,  0.0361,  0.0165,  0.0133],\n",
      "          [ 0.0457, -0.0169, -0.0449,  ..., -0.0326,  0.0575, -0.0383],\n",
      "          [-0.0683,  0.0620,  0.0682,  ..., -0.0225,  0.0005, -0.0464]],\n",
      "\n",
      "         [[-0.0575,  0.0059,  0.0678,  ..., -0.0690, -0.0329,  0.0663],\n",
      "          [ 0.0672,  0.0653,  0.0644,  ...,  0.0664,  0.0417, -0.0124],\n",
      "          [ 0.0007, -0.0683,  0.0250,  ..., -0.0049, -0.0664, -0.0316],\n",
      "          ...,\n",
      "          [ 0.0116, -0.0259,  0.0269,  ..., -0.0707, -0.0594,  0.0265],\n",
      "          [-0.0517, -0.0616,  0.0010,  ..., -0.0283,  0.0070,  0.0124],\n",
      "          [ 0.0433, -0.0526, -0.0101,  ...,  0.0457,  0.0304, -0.0294]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0449,  0.0643, -0.0459,  ..., -0.0538, -0.0087,  0.0356],\n",
      "          [ 0.0171,  0.0142, -0.0433,  ...,  0.0455,  0.0489,  0.0302],\n",
      "          [ 0.0153,  0.0641, -0.0451,  ..., -0.0365,  0.0507, -0.0084],\n",
      "          ...,\n",
      "          [ 0.0633,  0.0008,  0.0034,  ..., -0.0411, -0.0313, -0.0584],\n",
      "          [-0.0027, -0.0163,  0.0146,  ..., -0.0167, -0.0576,  0.0423],\n",
      "          [-0.0331,  0.0663,  0.0346,  ..., -0.0550,  0.0454,  0.0308]],\n",
      "\n",
      "         [[-0.0612,  0.0414, -0.0279,  ...,  0.0008,  0.0270, -0.0092],\n",
      "          [-0.0309,  0.0323,  0.0170,  ...,  0.0685,  0.0225,  0.0255],\n",
      "          [-0.0051,  0.0147, -0.0441,  ...,  0.0037,  0.0208, -0.0092],\n",
      "          ...,\n",
      "          [-0.0107,  0.0704,  0.0156,  ..., -0.0532,  0.0180,  0.0374],\n",
      "          [-0.0436,  0.0077, -0.0563,  ..., -0.0461,  0.0347,  0.0303],\n",
      "          [-0.0092,  0.0003,  0.0333,  ..., -0.0123, -0.0253, -0.0295]],\n",
      "\n",
      "         [[ 0.0585, -0.0174,  0.0206,  ..., -0.0576,  0.0139, -0.0481],\n",
      "          [ 0.0107,  0.0371,  0.0241,  ..., -0.0301, -0.0386,  0.0019],\n",
      "          [ 0.0169, -0.0084, -0.0134,  ...,  0.0276,  0.0237, -0.0469],\n",
      "          ...,\n",
      "          [ 0.0634, -0.0165, -0.0491,  ...,  0.0560,  0.0385,  0.0245],\n",
      "          [-0.0111,  0.0588,  0.0313,  ..., -0.0105, -0.0266,  0.0066],\n",
      "          [-0.0491, -0.0243, -0.0060,  ..., -0.0184, -0.0256, -0.0013]]]])\n"
     ]
    }
   ],
   "source": [
    "x = model.generator.resblocks[0].conv1.weight.data\n",
    "print(x.shape)\n",
    "x = x.permute(3,2,1,0)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weirdness Afoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result [[[[-0.61305225 -0.6804626   0.11569262  0.12916481]\n",
      "   [ 0.8744844  -0.25568002  0.18106008  0.34250492]\n",
      "   [-0.34760213  0.06820619 -0.5159601  -0.0028477 ]\n",
      "   [ 0.37385195 -0.13721271 -0.11608122 -0.18903476]]\n",
      "\n",
      "  [[ 0.06974803 -0.36361012 -0.70959246 -0.24128214]\n",
      "   [ 0.7637968   0.91365236 -0.5949327  -0.32401252]\n",
      "   [ 0.35629666 -0.38258404 -0.6643014  -0.8583082 ]\n",
      "   [ 0.55447584  0.08696834 -0.67363775  0.30926135]]\n",
      "\n",
      "  [[ 0.33146533 -0.11482179 -0.3043952   0.29770672]\n",
      "   [ 0.0145492   0.03810987 -1.1154032  -0.89013636]\n",
      "   [ 0.91061    -0.29720092 -0.5351878   0.23060244]\n",
      "   [ 0.19792801 -0.07683964 -0.39902225 -0.54844284]]\n",
      "\n",
      "  [[-0.0858967  -0.13297018 -0.38191897  0.20462504]\n",
      "   [-0.32521605 -0.13901548 -1.8993428  -0.43858945]\n",
      "   [-0.5998081   0.33009914 -1.0219332  -0.8117941 ]\n",
      "   [ 0.34582764  0.30031496 -1.4258046   0.06366794]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehdi2277/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "in_channels = 2\n",
    "out_channels = 4\n",
    "padding = 1\n",
    "kernel_size = 3\n",
    "\n",
    "x = np.random.random((1,4,4, in_channels))\n",
    "x_tf = tf.convert_to_tensor(x, tf.float32)\n",
    "x_py = torch.FloatTensor(np.transpose(x, [0, 3, 2, 1])) # I've also tried [0, 3, 2, 1]\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "# x_tf = tf.convert_to_tensor(x.permute(0,2,3,1).numpy(), dtype=tf.float32)\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer(uniform=True)\n",
    "conv_tf = tf.layers.conv2d(x_tf, filters=out_channels, kernel_size=kernel_size,\n",
    "                            padding='SAME', kernel_initializer=initializer)\n",
    "sess.run([tf.global_variables_initializer(),\n",
    "          tf.local_variables_initializer()])\n",
    "result = conv_tf.eval()\n",
    "print(\"result\", result)\n",
    "conv_weight = sess.run(tf.trainable_variables()[-2])\n",
    "conv_bias = sess.run(tf.trainable_variables()[-1])\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.6131, -0.6805,  0.1157,  0.1292],\n",
      "          [ 0.8745, -0.2557,  0.1811,  0.3425],\n",
      "          [-0.3476,  0.0682, -0.5160, -0.0028],\n",
      "          [ 0.3739, -0.1372, -0.1161, -0.1890]],\n",
      "\n",
      "         [[ 0.0697, -0.3636, -0.7096, -0.2413],\n",
      "          [ 0.7638,  0.9137, -0.5949, -0.3240],\n",
      "          [ 0.3563, -0.3826, -0.6643, -0.8583],\n",
      "          [ 0.5545,  0.0870, -0.6736,  0.3093]],\n",
      "\n",
      "         [[ 0.3315, -0.1148, -0.3044,  0.2977],\n",
      "          [ 0.0145,  0.0381, -1.1154, -0.8901],\n",
      "          [ 0.9106, -0.2972, -0.5352,  0.2306],\n",
      "          [ 0.1979, -0.0768, -0.3990, -0.5484]],\n",
      "\n",
      "         [[-0.0859, -0.1330, -0.3819,  0.2046],\n",
      "          [-0.3252, -0.1390, -1.8993, -0.4386],\n",
      "          [-0.5998,  0.3301, -1.0219, -0.8118],\n",
      "          [ 0.3458,  0.3003, -1.4258,  0.0637]]]], grad_fn=<PermuteBackward>)\n"
     ]
    }
   ],
   "source": [
    "conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "conv.weight.data = torch.tensor(conv_weight).permute(3,2,1,0).contiguous()\n",
    "conv.bias.data = torch.tensor(conv_bias).contiguous()    \n",
    "py_result = conv(x_py).permute(0,3,2,1) # Rearange for comparison with tensorflow\n",
    "print(py_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4, 4])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "all_perms = list(itertools.permutations([1,2,3]))\n",
    "for perm in all_perms:\n",
    "    perm_result = py_result.permute(0, *perm)\n",
    "    print(perm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weirdness Ends Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.109498761309169e-06\n"
     ]
    }
   ],
   "source": [
    "# # FROM SOME SO POST\n",
    "# import model\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# sess = tf.Session()\n",
    "# np.random.seed(1)\n",
    "# tf.set_random_seed(1)\n",
    "\n",
    "# #parameters\n",
    "# kernel_size = 3\n",
    "# input_feat = 4\n",
    "# output_feat = 4\n",
    "\n",
    "# #inputs\n",
    "# npo = np.random.random((1,5,5, input_feat))\n",
    "# x = tf.convert_to_tensor(npo, tf.float32)\n",
    "# x2 = torch.tensor(np.transpose(npo, [0, 3, 2, 1])).double()\n",
    "\n",
    "# #the same weights\n",
    "# weights = np.random.random((kernel_size,kernel_size,input_feat,output_feat))\n",
    "# weights_torch = np.transpose(weights, [3, 2, 1, 0])\n",
    "\n",
    "# #convolving with tensorflow\n",
    "# w = tf.Variable(weights, name=\"testconv_W\", dtype=tf.float32)\n",
    "# res = tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# #convolving with torch\n",
    "# torchres = F.conv2d(x2, torch.tensor(weights_torch), padding=0, bias=torch.zeros((output_feat)).double())\n",
    "\n",
    "# #comparing the results\n",
    "# print(np.mean(np.transpose(sess.run(res), [0, 3, 1, 2])) - torch.mean(torchres).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8, 8, 128)\n"
     ]
    }
   ],
   "source": [
    "# v = torch.tensor(np.load(\"params/generator_conv2d_kernel:0.npy\")).permute(3,2,1,0)\n",
    "# print(v.shape)\n",
    "print(tf_bn_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65031743 -0.6203244  -0.49183062  0.5059358   0.28351417 -1.2729391\n",
      " -0.0390036  -0.7468238   0.6516546  -1.204329    0.0734973  -0.02232832\n",
      "  0.3725338  -0.08989799 -0.00615811  0.4278187  -0.09832315  0.29158783\n",
      "  0.84003997  0.04280537 -1.0682315   0.1907023  -0.36410913  1.5561202\n",
      " -0.12220084  0.02108081  0.01915061  1.4213235   0.09183311 -0.36637288\n",
      " -0.23123804  0.5040692   0.97450817 -0.2969277  -0.94745934  1.1106435\n",
      " -0.07927477  0.82612944 -0.1617369   0.18703566 -0.6548972   0.8209766\n",
      " -0.31261256  0.35590196  0.09823444 -1.3237336   0.7239871   0.6121413\n",
      " -0.36086214  0.1626235  -0.26243168  0.5572176   1.4531343   0.5239057\n",
      "  0.84014416  1.1397151   0.36312747  1.3075147  -1.1382031  -0.22748637\n",
      "  0.5468823  -0.10433887 -1.0650768   0.06931782  0.47596106  1.3198633\n",
      " -0.42912716  0.73430645 -0.62745625 -1.3099842  -0.75498706  0.4060669\n",
      " -0.8465472  -0.22658643 -0.16979995  0.18600342  0.03421217  0.7452529\n",
      " -0.54868406 -0.33201602 -0.25047937  0.40531865  1.1708739   0.47588867\n",
      "  0.23001108 -0.01239575  0.7793306   0.1531826  -0.49301082 -0.41627824\n",
      " -0.23131272  0.33799487  0.06784341  0.15527663  0.99868596  0.44655824\n",
      " -0.24247494  0.7560802   0.33784068 -0.06005937  0.37819204  0.4026142\n",
      " -0.43621638 -0.5469834   0.81398463  0.33919013  0.34828496  0.123173\n",
      " -0.24943049  0.21702561 -0.25295076  0.45859128  0.15234405 -0.94907784\n",
      "  0.38161647  0.20405725  1.0426761   0.58833313 -0.6794893  -0.6411562\n",
      "  1.1833193  -0.04689184  1.1480465   1.1170472   1.2028419   0.2361248\n",
      " -0.26573506 -0.28327107]\n",
      "==================================================================\n",
      "[ 0.65031767 -0.6203243  -0.49183077  0.50593585  0.28351414 -1.2729385\n",
      " -0.03900354 -0.7468237   0.65165484 -1.2043289   0.0734974  -0.0223284\n",
      "  0.37253398 -0.08989806 -0.00615823  0.42781886 -0.09832329  0.29158768\n",
      "  0.8400404   0.04280567 -1.0682317   0.1907021  -0.364109    1.5561206\n",
      " -0.12220084  0.02108102  0.01915057  1.4213227   0.09183297 -0.36637324\n",
      " -0.23123811  0.50406915  0.9745077  -0.2969279  -0.9474596   1.1106441\n",
      " -0.079275    0.82612926 -0.1617369   0.18703546 -0.6548973   0.8209763\n",
      " -0.31261256  0.35590208  0.09823445 -1.3237338   0.7239871   0.61214113\n",
      " -0.36086243  0.16262351 -0.26243135  0.5572179   1.4531342   0.5239056\n",
      "  0.84014416  1.1397151   0.36312744  1.3075147  -1.1382031  -0.22748652\n",
      "  0.54688233 -0.10433876 -1.0650772   0.0693177   0.47596097  1.3198636\n",
      " -0.429127    0.7343063  -0.6274565  -1.309984   -0.75498736  0.4060667\n",
      " -0.8465474  -0.22658612 -0.16980001  0.18600334  0.03421235  0.745253\n",
      " -0.5486839  -0.3320159  -0.2504793   0.4053187   1.170874    0.4758888\n",
      "  0.23001108 -0.01239575  0.7793309   0.15318263 -0.4930107  -0.41627854\n",
      " -0.23131257  0.33799428  0.06784339  0.1552767   0.9986865   0.4465583\n",
      " -0.24247472  0.7560802   0.33784068 -0.06005913  0.37819177  0.40261433\n",
      " -0.43621665 -0.5469833   0.81398416  0.33919013  0.348285    0.12317312\n",
      " -0.24943036  0.21702574 -0.25295085  0.45859122  0.15234397 -0.9490778\n",
      "  0.38161656  0.2040573   1.0426761   0.588333   -0.6794891  -0.64115614\n",
      "  1.1833191  -0.04689192  1.1480466   1.1170475   1.2028419   0.23612505\n",
      " -0.265735   -0.28327113]\n"
     ]
    }
   ],
   "source": [
    "print(tf_bn_input[0, 0, 0,:])\n",
    "print(\"===\"*22)\n",
    "print(py_bn_input[0, 0, 0,:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46407175 -0.29227483  0.26989132  0.51021767  0.5166483  -0.05000585\n",
      " -0.08072945  0.04050548 -0.36849916 -0.19898066 -0.8010465  -0.23489217\n",
      " -0.4345651   0.6034463  -0.25511673  0.6966145   1.2504725  -0.08049522\n",
      " -0.26976836 -1.2811017  -0.5883877   0.0571833   0.12746903  0.8738511\n",
      "  1.5349185  -0.15438713 -1.4112797   0.9779048   0.40282556 -1.927623\n",
      " -0.38846087  0.0151476   1.437269   -1.5116789  -0.3965437   1.2025797\n",
      " -0.09323318  0.6826073   0.8670521   0.35153592 -0.9071082   0.3013622\n",
      " -0.14124417  0.19807327 -0.26500982 -0.11583344  1.0241275   1.1238248\n",
      "  0.7542276  -0.83686686 -0.95186037  0.658851    1.2842011   1.5170897\n",
      "  0.4500775  -0.1398077   0.9256458   0.5818185  -0.44643986 -0.18722752\n",
      "  0.84645057  0.55748576 -0.47237825 -0.14010607 -0.5915407   0.15492344\n",
      " -0.03601738  0.19088033 -0.27634692  0.77118975  0.25651816  0.18324804\n",
      "  0.446023    0.40662053  0.07430738  0.03888976  0.00274904 -0.06280538\n",
      " -1.3808008   0.40904635 -1.8467833   0.7404522  -0.10125342  0.6558882\n",
      " -0.26763755  0.03316553  0.9153766   0.02543154 -0.70523167 -1.7078826\n",
      " -0.1894481  -1.3673319   0.7175849   1.3834022   1.360647   -0.1415219\n",
      " -0.27303702  0.29004142  1.426009    0.955891   -1.3866028  -0.57591724\n",
      "  0.72555363 -0.46459174 -0.2047372  -0.7491201   0.3908525   0.21117485\n",
      " -0.72956437 -0.3347907  -0.2133687   0.08991983  0.50241196  0.8710132\n",
      "  1.0209447   1.233202    1.2040533  -0.05172822  0.02218756 -0.32851085\n",
      "  1.0779829   0.10264063  1.4461932  -0.71337736  0.38275528 -0.2221751\n",
      "  0.41733235 -0.83643425] 4\n",
      "==================================================================\n",
      "[-0.21260838 -1.34687    -0.33490932 -0.14794438 -0.34456748 -0.9574158\n",
      "  0.67617345 -0.4628254  -0.13606651 -0.5687997  -0.90933037 -0.33506626\n",
      "  0.8028478   0.33416837 -0.9054186  -0.05970036  0.96579796  0.28167194\n",
      "  0.49450758 -0.38580474 -0.38031006  0.94121414  0.04347058  3.1094408\n",
      "  0.26651645 -0.7912064   0.64830214  0.7014487   0.93845046 -0.33072495\n",
      " -0.6562093   0.57742566  0.7712046  -0.26916936 -0.6343815   1.3209395\n",
      " -0.700406    2.2349281  -0.61466134  0.08419549 -0.62305     0.55345595\n",
      "  0.02206547  0.47691736  0.6253171  -0.34641945  0.7072513   0.14528142\n",
      "  0.3492004   0.6211337  -0.01965998 -0.23130895  1.1516352   1.0888048\n",
      "  0.8840479   1.1401091   1.2776425  -0.03670503 -0.8069044  -1.1814079\n",
      "  0.40679538  0.91982216  0.24737132  0.80403817 -0.14907292  0.4048085\n",
      " -0.12742497  0.3878034  -0.14281747 -1.0051223  -0.1652972  -0.12979676\n",
      " -1.0744075   0.0285261  -0.29054365 -0.54841775  0.6111069   0.0678773\n",
      " -1.6253757  -0.38140863  0.23779653  1.3196038   0.417463    0.01391392\n",
      "  0.03451703  1.0048374   0.89780724  0.4279992  -0.15498063 -0.28742278\n",
      " -0.04152433 -0.97467417 -0.6916257   0.2896752   0.11857295  0.8856308\n",
      "  0.44166294  1.0175277  -0.6570836   1.1023083   0.22438541  0.06330282\n",
      "  1.1206013   0.5761171   1.6557798   1.2454927   1.6305764  -0.3101253\n",
      " -0.01340663  0.3453549  -1.6491443  -1.1260519  -0.5495287  -0.52408427\n",
      " -0.07792097  0.4385786   0.02036252 -0.81033504  0.02410701  0.12378817\n",
      "  1.3773918   0.7472168   1.4850703  -0.24192268  0.7827203  -0.3747768\n",
      " -0.12999931  0.11820845]\n"
     ]
    }
   ],
   "source": [
    "print(tf_bn_input[0, 0, 1,:])\n",
    "print(\"===\"*22)\n",
    "print(py_bn_input[0, 0, 1,:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py_out = vec1.permute(0,2,3,1).contiguous()\n",
    "# tf_out = np.load(\"bn_output.npy\")\n",
    "# # print(py_up.shape, tf_up.shape)\n",
    "# # print(np.array_equal(tf_up, py_up.cpu().detach().numpy()))\n",
    "# print(tf_out[0,:4,:4,:4])\n",
    "# print(\"   \\n\" * 3)\n",
    "# print(py_out[0,:4,:4,:4])\n",
    "# print(\"======\\n\" * 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
