{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADset(Dataset):\n",
    "    def __init__(self, files_list):\n",
    "        self.images = files_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY ASSUMES BGR AND -1 TO 1\n",
    "def get_files(start=None, stop=None, augment=True, shape=(64,64)):\n",
    "    files_list = []\n",
    "    i = 0\n",
    "    for file in os.listdir(\"img_align_celeba\")[start: stop]:\n",
    "        if not i % 1000:\n",
    "            print(i)\n",
    "        img = cv2.imread(\"img_align_celeba/\" + file)\n",
    "        y_start = 50\n",
    "        x_start = 25\n",
    "        crop_size = 128\n",
    "        img = img[y_start:y_start + crop_size, x_start:x_start + crop_size]\n",
    "        img = cv2.resize(img, shape)\n",
    "        img = np.moveaxis(img, 2, 0)\n",
    "        if augment: \n",
    "            should_flip = random.randint(0, 1) == 1\n",
    "            if should_flip:\n",
    "                img = np.moveaxis(img, 1, 2)\n",
    "            c, h, w = img.shape\n",
    "            noise = torch.FloatTensor(c, h, w).uniform_(0, 1/256)\n",
    "            img = img / 256\n",
    "            temp = torch.FloatTensor(img)\n",
    "            img = torch.FloatTensor(img) + noise\n",
    "        else:\n",
    "            img = torch.FloatTensor(img)\n",
    "            img = img / 255\n",
    "        img = (img - 0.5) * 2\n",
    "        i += 1\n",
    "        files_list.append(img)\n",
    "    random.shuffle(files_list)\n",
    "    return files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 202599\n",
    "TRAIN_STOP = 162770\n",
    "VAL_STOP = 182637\n",
    "\n",
    "def format_celeba(shape=(64, 64), split=None, augment=True):\n",
    "    if split is None:\n",
    "        files = get_files(shape=shape)\n",
    "    elif split == 'train':\n",
    "        files = get_files(0, TRAIN_STOP, shape=shape, augment=augment)\n",
    "    elif split == 'val':\n",
    "        files = get_files(TRAIN_STOP, VAL_STOP, shape=shape, augment=augment)\n",
    "    elif split == 'test':\n",
    "        files = get_files(VAL_STOP, shape=shape, augment=augment)\n",
    "    else:\n",
    "        raise ValueError('unknown split')\n",
    "        \n",
    "    dataset = CelebADset(files)\n",
    "    return dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = format_celeba(split='train')\n",
    "# val_dset = format_celeba(split='val')\n",
    "test_dset = format_celeba(split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"celeba_64_bgr_-1_to_1_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_dset, f, protocol=2)\n",
    "# with open(\"celeba_64_bgr_-1_to_1_val.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(val_dset, f)\n",
    "# with open(\"celeba_64_bgr_-1_to_1_test.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(test_dset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = train_dset.images\n",
    "segment = len(train_dset) // 5\n",
    "for i in range(5):\n",
    "    with open(\"celeba_64_bgr_-1_to_1_train_part%i.pkl\" %i, \"wb\") as f:\n",
    "        pickle.dump(files_list[segment * i:segment * (i + 1)], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADset(Dataset):\n",
    "    def __init__(self, files_list):\n",
    "        self.images = files_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_param(v):\n",
    "    print(\"Name: \", v.name)\n",
    "    vector = sess.run(v)\n",
    "    print(\"Shape: \", v.shape)\n",
    "    print(vector)\n",
    "    print(\"=\" * 20)\n",
    "    name = v.name.replace(\"/\", \"_\")\n",
    "    np.save(\"params/\" + name, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2, 2)\n",
      "[[[[-0.22473314 -1.3034523 ]\n",
      "   [ 0.85398597 -0.94387925]]\n",
      "\n",
      "  [[-0.30661756  0.37876284]\n",
      "   [ 2.4709768   0.01803633]]]\n",
      "\n",
      "\n",
      " [[[-1.3034523   0.85398597]\n",
      "   [ 0.85398597  1.213559  ]]\n",
      "\n",
      "  [[-0.7034167  -0.59519875]\n",
      "   [-0.7034167  -0.55912614]]]]\n",
      "Name:  BatchNorm/gamma:0\n",
      "Shape:  (3,)\n",
      "[1. 1. 1.]\n",
      "====================\n",
      "Name:  BatchNorm/beta:0\n",
      "Shape:  (3,)\n",
      "[0. 0. 0.]\n",
      "====================\n",
      "Name:  BatchNorm_1/gamma:0\n",
      "Shape:  (2,)\n",
      "[1. 1.]\n",
      "====================\n",
      "Name:  BatchNorm_1/beta:0\n",
      "Shape:  (2,)\n",
      "[0. 0.]\n",
      "====================\n",
      "Name:  BatchNorm_2/gamma:0\n",
      "Shape:  (2,)\n",
      "[1. 1.]\n",
      "====================\n",
      "Name:  BatchNorm_2/beta:0\n",
      "Shape:  (2,)\n",
      "[0. 0.]\n",
      "====================\n",
      "Name:  BatchNorm_3/gamma:0\n",
      "Shape:  (2,)\n",
      "[1. 1.]\n",
      "====================\n",
      "Name:  BatchNorm_3/beta:0\n",
      "Shape:  (2,)\n",
      "[0. 0.]\n",
      "====================\n",
      "Name:  BatchNorm_4/gamma:0\n",
      "Shape:  (2,)\n",
      "[1. 1.]\n",
      "====================\n",
      "Name:  BatchNorm_4/beta:0\n",
      "Shape:  (2,)\n",
      "[0. 0.]\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = np.array([[[[3., 0.],\n",
    "   [6., 1.]],\n",
    "\n",
    "#   [[0., 2.],\n",
    "#    [4., 0.]],\n",
    "\n",
    "  [[11., 30.],\n",
    "   [88. ,20.]]],\n",
    "\n",
    "\n",
    " [[[0., 6.],\n",
    "   [6. ,7.]],\n",
    "\n",
    "#   [[1., 110.],\n",
    "#    [2. ,20.]],\n",
    "\n",
    "  [[0., 3.],\n",
    "   [0. ,4.]]]])\n",
    "print(x.shape)\n",
    "\n",
    "tf_arr = np.moveaxis(x, 1, 3)\n",
    "tf_arr = tf.convert_to_tensor(tf_arr, dtype=tf.float32)\n",
    "bn = tf.contrib.layers.batch_norm(tf_arr, decay=0.9, # OK\n",
    "                                    center=True, # OK\n",
    "                                    scale=True, #OK\n",
    "                                    epsilon=1e-5,#OK\n",
    "                                    zero_debias_moving_mean=False,\n",
    "                                    is_training=True)\n",
    "sess.run([tf.global_variables_initializer(),\n",
    "          tf.local_variables_initializer()])\n",
    "bn_eval = bn.eval()\n",
    "bn_comparable = np.moveaxis(bn_eval, 3, 1)\n",
    "print(bn_comparable)\n",
    "[print_param(v) for v in tf.trainable_variables() ]\n",
    "sess.close()\n",
    "\n",
    "#0000, 1001 --> same val = same; x__x\n",
    "#1100, 1110 --> same val = same  __x_ 1000\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-2.24733287e-01 -7.03416701e-01]\n",
      "   [ 8.53986492e-01 -6.67344050e-01]]\n",
      "\n",
      "  [[ 2.65185279e+00  3.78762839e-01]\n",
      "   [ 3.03389938e+01  1.80363257e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.30345307e+00 -4.86980793e-01]\n",
      "   [ 8.53986492e-01 -4.50908142e-01]]\n",
      "\n",
      "  [[-1.30345307e+00 -5.95198747e-01]\n",
      "   [-1.30345307e+00 -5.59126096e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "m = np.mean(x, axis=(0,2,3))\n",
    "v = np.std(x, axis=(0,2,3))\n",
    "print((x - m)/v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2247, -1.3035],\n",
      "          [ 0.8540, -0.9439]],\n",
      "\n",
      "         [[-0.3066,  0.3788],\n",
      "          [ 2.4710,  0.0180]]],\n",
      "\n",
      "\n",
      "        [[[-1.3035,  0.8540],\n",
      "          [ 0.8540,  1.2136]],\n",
      "\n",
      "         [[-0.7034, -0.5952],\n",
      "          [-0.7034, -0.5591]]]], grad_fn=<NativeBatchNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "# PYTORCH\n",
    "batchnorm = nn.BatchNorm2d(2, eps=1e-5)\n",
    "# batchnorm.training=False\n",
    "nn.init.constant_(batchnorm.weight, 1)\n",
    "torch_arr = torch.FloatTensor(x)\n",
    "torch_bn = batchnorm(torch_arr)\n",
    "print(torch_bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = torch.mean(torch_arr, dim=(1,2,3))\n",
    "# # v = torch_arr.permute(1,0,2,3)\n",
    "# v = torch_arr.contiguous().view(v.size(0), -1)\n",
    "# v = torch.var(v, 1)\n",
    "\n",
    "\n",
    "# print(m.shape)\n",
    "# print(v.shape)\n",
    "# print(torch.nn.functional.batch_norm(torch_arr, m, v))\n",
    "\n",
    "\n",
    "# # 0\n",
    "# # 1 X\n",
    "# # 2\n",
    "# # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.var(torch_arr, dim=1)[:,0,0]#, dim=(0,2,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
