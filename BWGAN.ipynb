{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9746b90130>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     3,
     20,
     25
    ]
   },
   "outputs": [],
   "source": [
    "def upsample(x):\n",
    "    return nn.functional.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "def downsample(x):\n",
    "    return nn.functional.interpolate(x, scale_factor=0.5, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "def conv_layer(in_filters, out_filters=32, kernel_size=3, he_init=True):\n",
    "    same_padding = (kernel_size-1)//2\n",
    "    conv = nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, padding=same_padding)\n",
    "    \n",
    "    if he_init:\n",
    "        he_init_constant = math.sqrt(6 / (in_filters * kernel_size**2))\n",
    "        nn.init.uniform_(conv.weight, -he_init_constant, he_init_constant)\n",
    "    else:\n",
    "        xavier_init_constant = math.sqrt(6 / ((in_filters + out_filters) * kernel_size**2))\n",
    "        nn.init.uniform_(conv.weight, -xavier_init_constant, xavier_init_constant)\n",
    "    nn.init.constant_(conv.bias, 0)\n",
    "    \n",
    "    return conv\n",
    "\n",
    "def bn(channels):\n",
    "    batchnorm = nn.BatchNorm2d(channels, eps=1e-5)\n",
    "    nn.init.constant_(batchnorm.weight, 1)\n",
    "    return batchnorm\n",
    "\n",
    "def linear(in_features, out_features):\n",
    "    linear_layer = nn.Linear(in_features, out_features)\n",
    "    \n",
    "    xavier_init_constant = math.sqrt(6/(in_features+out_features))\n",
    "    nn.init.uniform_(linear_layer.weight, -xavier_init_constant, xavier_init_constant)\n",
    "    nn.init.constant_(linear_layer.bias, 0)\n",
    "    \n",
    "    return linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     55
    ]
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, resample=None, normalize=False, activation=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.in_filters = in_filters\n",
    "        self.out_filters = out_filters\n",
    "        self.resample = resample\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        self.conv1 = conv_layer(in_filters, out_filters)\n",
    "        self.conv2 = conv_layer(out_filters, out_filters)\n",
    "        \n",
    "        if resample:\n",
    "            self.conv3 = conv_layer(in_filters, out_filters, kernel_size=1, he_init=False)\n",
    "        \n",
    "        if normalize:\n",
    "            self.bn1 = bn(in_filters)\n",
    "            self.bn2 = bn(out_filters)\n",
    "            \n",
    "        if activation is not None:\n",
    "            self.activation = activation\n",
    "        else:\n",
    "            self.activation = nn.ReLU()\n",
    "                \n",
    "    def forward(self, x): \n",
    "        orig_input = x\n",
    "        \n",
    "        if self.normalize:\n",
    "            x = self.bn1(x)\n",
    "            \n",
    "        x = self.activation(x)\n",
    "        \n",
    "        if self.resample == 'up':\n",
    "            x = upsample(x)\n",
    "       \n",
    "        x = self.conv1(x)\n",
    "\n",
    "        if self.normalize:\n",
    "            x = self.bn2(x)\n",
    "            \n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        if self.resample == 'down':\n",
    "            x = downsample(x)\n",
    "        \n",
    "        # Shortcut\n",
    "        if self.resample == 'down': \n",
    "            shortcut_x = downsample(self.conv3(orig_input))\n",
    "        elif self.resample == 'up':\n",
    "            shortcut_x = self.conv3(upsample(orig_input))\n",
    "        elif self.resample == None:\n",
    "            shortcut_x = orig_input\n",
    "        \n",
    "        return x + shortcut_x\n",
    "    \n",
    "class SmallResBlock(nn.Module):\n",
    "    def __init__(self, in_filters, out_filters, activation=None):\n",
    "        super(SmallResBlock, self).__init__()\n",
    "        self.in_filters = in_filters\n",
    "        self.out_filters = out_filters\n",
    "        \n",
    "        self.conv1 = conv_layer(in_filters, out_filters)\n",
    "        self.conv2 = conv_layer(out_filters, out_filters)\n",
    "        self.conv3 = conv_layer(in_filters, out_filters, kernel_size=1, he_init=False)\n",
    "            \n",
    "        if activation is not None:\n",
    "            self.activation = activation\n",
    "        else:\n",
    "            self.activation = nn.ReLU()\n",
    "                \n",
    "    def forward(self, x): \n",
    "        orig_input = x\n",
    "       \n",
    "        x = self.conv1(x)   \n",
    "        x = downsample(self.conv2(self.activation(x)))\n",
    "\n",
    "        # Shortcut\n",
    "        shortcut_x = self.conv3(downsample(orig_input))\n",
    "        \n",
    "        return x + shortcut_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, num_filters=128, num_blocks=3, start_image_size=4, num_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.num_filters = num_filters\n",
    "        self.start_image_size = start_image_size\n",
    "        \n",
    "        self.first_linear = linear(input_size, num_filters * start_image_size ** 2)\n",
    "        self.resblocks = nn.ModuleList()\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        for _ in range(num_blocks):\n",
    "            self.resblocks.append(\n",
    "                ResBlock(in_filters=self.num_filters, \n",
    "                         out_filters=self.num_filters, \n",
    "                         resample='up', \n",
    "                         normalize=True))\n",
    "            \n",
    "        self.last_layer = conv_layer(num_filters, num_channels)\n",
    "        self.bn = bn(num_filters)\n",
    "        self.manually_initialize()\n",
    "    \n",
    "    def forward(self, noise):        \n",
    "        x = self.first_linear(noise)\n",
    "        \n",
    "        x = x.view(-1, self.start_image_size, self.start_image_size, self.num_filters)\n",
    "        x = x.permute(0, 3, 2, 1) # these last two lines could be simplified but tf consistency forces this.\n",
    "        \n",
    "        for resblock in self.resblocks:\n",
    "            x = resblock(x)\n",
    "            \n",
    "        x = self.activation(self.bn(x))\n",
    "        result = self.last_layer(x)\n",
    "        return torch.tanh(result)\n",
    "    \n",
    "    def manually_initialize(self):\n",
    "        self.first_linear.weight.data = torch.tensor(np.load(\"params/generator_dense_kernel:0.npy\")).transpose(0,1).contiguous()\n",
    "        self.first_linear.bias.data = torch.tensor(np.load(\"params/generator_dense_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[0].bn1.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_gamma:0.npy\"))\n",
    "        self.resblocks[0].bn1.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_beta:0.npy\"))\n",
    "        \n",
    "        self.resblocks[0].bn2.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_1_gamma:0.npy\"))\n",
    "        self.resblocks[0].bn2.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_1_beta:0.npy\"))\n",
    "        \n",
    "        self.resblocks[1].bn1.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_2_gamma:0.npy\"))\n",
    "        self.resblocks[1].bn1.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_2_beta:0.npy\"))\n",
    "        \n",
    "        self.resblocks[1].bn2.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_3_gamma:0.npy\"))\n",
    "        self.resblocks[1].bn2.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_3_beta:0.npy\"))\n",
    "        \n",
    "        self.resblocks[2].bn1.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_4_gamma:0.npy\"))\n",
    "        self.resblocks[2].bn1.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_4_beta:0.npy\"))\n",
    "        \n",
    "        self.resblocks[2].bn2.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_5_gamma:0.npy\"))\n",
    "        self.resblocks[2].bn2.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_5_beta:0.npy\"))\n",
    "        \n",
    "        self.bn.weight.data = torch.tensor(np.load(\"params/generator_BatchNorm_6_gamma:0.npy\"))\n",
    "        self.bn.bias.data = torch.tensor(np.load(\"params/generator_BatchNorm_6_beta:0.npy\"))\n",
    "        \n",
    "        self.resblocks[0].conv1.weight.data = torch.tensor(np.load(\"params/generator_conv2d_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[0].conv1.bias.data = torch.tensor(np.load(\"params/generator_conv2d_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[0].conv2.weight.data = torch.tensor(np.load(\"params/generator_conv2d_1_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[0].conv2.bias.data = torch.tensor(np.load(\"params/generator_conv2d_1_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[0].conv3.weight.data = torch.tensor(np.load(\"params/generator_conv2d_2_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[0].conv3.bias.data = torch.tensor(np.load(\"params/generator_conv2d_2_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[1].conv1.weight.data = torch.tensor(np.load(\"params/generator_conv2d_3_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[1].conv1.bias.data = torch.tensor(np.load(\"params/generator_conv2d_3_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[1].conv2.weight.data = torch.tensor(np.load(\"params/generator_conv2d_4_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[1].conv2.bias.data = torch.tensor(np.load(\"params/generator_conv2d_4_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[1].conv3.weight.data = torch.tensor(np.load(\"params/generator_conv2d_5_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[1].conv3.bias.data = torch.tensor(np.load(\"params/generator_conv2d_5_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[2].conv1.weight.data = torch.tensor(np.load(\"params/generator_conv2d_6_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[2].conv1.bias.data = torch.tensor(np.load(\"params/generator_conv2d_6_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[2].conv2.weight.data = torch.tensor(np.load(\"params/generator_conv2d_7_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[2].conv2.bias.data = torch.tensor(np.load(\"params/generator_conv2d_7_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[2].conv3.weight.data = torch.tensor(np.load(\"params/generator_conv2d_8_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[2].conv3.bias.data = torch.tensor(np.load(\"params/generator_conv2d_8_bias:0.npy\"))\n",
    "        \n",
    "        self.last_layer.weight.data = torch.tensor(np.load(\"params/generator_conv2d_9_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.last_layer.bias.data = torch.tensor(np.load(\"params/generator_conv2d_9_bias:0.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLPLayer, self).__init__()\n",
    "        self.block = nn.Sequential(linear(input_size, output_size), nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class VectorDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_blocks):\n",
    "        super(VectorDiscriminator, self).__init__()\n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.blocks.append(MLPLayer(input_size, hidden_size))\n",
    "        \n",
    "        for _ in range(num_blocks - 1):\n",
    "            self.blocks.append(hidden_size, hidden_size)\n",
    "        \n",
    "        self.blocks.append(linear(hidden_size, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ImageDiscriminator(nn.Module):\n",
    "    def __init__(self, num_filters=128, num_blocks=4, num_channels=3):\n",
    "        super(ImageDiscriminator, self).__init__()\n",
    "        assert num_blocks >= 2, \"Number of conv layers in the discriminator must be >= 2.\"\n",
    "        \n",
    "        self.resblocks = nn.ModuleList()\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        self.resblocks.append(SmallResBlock(in_filters=num_channels, \n",
    "                                            out_filters=num_filters))\n",
    "        self.resblocks.append(ResBlock(in_filters=num_filters, \n",
    "                                       out_filters=num_filters, \n",
    "                                       resample='down'))\n",
    "        for _ in range(num_blocks - 2):\n",
    "            self.resblocks.append(ResBlock(in_filters=num_filters, \n",
    "                                           out_filters=num_filters))\n",
    "            \n",
    "        self.last_linear = linear(num_filters, 1)\n",
    "        self.manually_initialize()\n",
    "   \n",
    "    def forward(self, x):\n",
    "        for resblock in self.resblocks:\n",
    "            x = resblock(x)\n",
    "            \n",
    "        x = self.activation(x)\n",
    "        x = x.mean(dim=(-1,-2))\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "    \n",
    "    def manually_initialize(self):\n",
    "        self.last_linear.weight.data = torch.tensor(np.load(\"params/discriminator_dense_kernel:0.npy\")).transpose(0,1).contiguous()\n",
    "        self.last_linear.bias.data = torch.tensor(np.load(\"params/discriminator_dense_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[0].conv1.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[0].conv1.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[0].conv2.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_1_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[0].conv2.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_1_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[0].conv3.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_2_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[0].conv3.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_2_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[1].conv1.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_3_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[1].conv1.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_3_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[1].conv2.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_4_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[1].conv2.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_4_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[1].conv3.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_5_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[1].conv3.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_5_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[2].conv1.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_6_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[2].conv1.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_6_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[2].conv2.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_7_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[2].conv2.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_7_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[3].conv1.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_8_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[3].conv1.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_8_bias:0.npy\"))\n",
    "        \n",
    "        self.resblocks[3].conv2.weight.data = torch.tensor(np.load(\"params/discriminator_conv2d_9_kernel:0.npy\")).permute(3,2,1,0).contiguous()\n",
    "        self.resblocks[3].conv2.bias.data = torch.tensor(np.load(\"params/discriminator_conv2d_9_bias:0.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def identity_embedding(pic):\n",
    "    return pic\n",
    "\n",
    "class WGAN(nn.Module):\n",
    "    def __init__(self, gamma, noise_size=128, num_filters=128, num_generator_blocks=3, num_discriminator_blocks=4,\n",
    "                 batch_size=64, num_channels=3, discriminator_epsilon=1e-5, embedding_size=None, \n",
    "                 discriminator_hidden_size=None, discriminator_type=\"Image\"):  \n",
    "        super(WGAN, self).__init__()\n",
    "        self.generator = Generator(noise_size, num_filters=num_filters, num_blocks=num_generator_blocks,\n",
    "                                   start_image_size=4, num_channels=num_channels)\n",
    "        \n",
    "        if discriminator_type == \"Image\":\n",
    "            self.discriminator = ImageDiscriminator(num_filters=num_filters, num_blocks=num_discriminator_blocks, \n",
    "                                                    num_channels=num_channels)\n",
    "        elif discriminator_type == \"Vector\":\n",
    "            self.discriminator = VectorDiscriminator(input_size=embedding_size, \n",
    "                                                     hidden_size=discriminator_hidden_size,\n",
    "                                                     num_blocks=num_discriminator_blocks)\n",
    "        else:\n",
    "            raise ValueError(\"Discriminator type not recognized.\")\n",
    "        self.discriminator_epsilon = discriminator_epsilon\n",
    "        \n",
    "        # Assumption that the dual space is the same as the original space.\n",
    "        self.gamma = gamma\n",
    "        self.lambda_penalty = gamma\n",
    "        \n",
    "        self.register_buffer(\"penalty_grad_outputs\", torch.ones(batch_size))\n",
    "        self.register_buffer(\"noise_buffer\", torch.ones((batch_size, noise_size)))\n",
    "        self.register_buffer(\"epsilon_buffer\", torch.ones(batch_size, 1, 1, 1))\n",
    "        \n",
    "    def forward_train_generator(self, noise=None):\n",
    "        generated_image = self.forward_predict_generator(noise)\n",
    "        discriminator_score_generated = self.forward_predict_discriminator(generated_image)\n",
    "        return self.generator_loss(discriminator_score_generated)\n",
    "    \n",
    "    def forward_train_discriminator(self, real_images, noise=None):\n",
    "        generated_images = self.forward_predict_generator(noise)\n",
    "        discriminator_score_generated = self.forward_predict_discriminator(generated_images)\n",
    "        discriminator_score_real = self.forward_predict_discriminator(real_images)\n",
    "        return self.discriminator_loss(discriminator_score_real, discriminator_score_generated, \n",
    "                                       real_images, generated_images)\n",
    "        \n",
    "    def forward_predict_generator(self, noise=None):\n",
    "        if noise is None:\n",
    "            noise = self.generate_noise()\n",
    "        return self.generator(noise)\n",
    "        \n",
    "    def forward_predict_discriminator(self, images):\n",
    "        return self.discriminator(images)\n",
    "    \n",
    "    def generate_noise(self):\n",
    "        return torch.randn_like(self.noise_buffer)\n",
    "    \n",
    "    def generator_loss(self, d_score_generated):\n",
    "        return torch.mean(d_score_generated) / self.gamma \n",
    "    \n",
    "    def stable_norm(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        alpha, _ = (x.abs() + 1e-5).max(1)\n",
    "        \n",
    "        return alpha * (x/alpha.unsqueeze(1)).norm(p=2, dim=1)\n",
    "    \n",
    "    def gradient_penalty(self, real_fake_mix):\n",
    "        d_score_mix = self.discriminator(real_fake_mix).squeeze(1)\n",
    "        \n",
    "        gradients = torch.autograd.grad(d_score_mix, real_fake_mix, grad_outputs=self.penalty_grad_outputs,\n",
    "                                        create_graph=True)[0]\n",
    "        gradient_penalty = self.lambda_penalty * torch.mean(self.stable_norm(gradients) / gamma - 1) ** 2\n",
    "        return gradient_penalty\n",
    "    \n",
    "    def discriminator_loss(self, d_score_real, d_score_generated, real_images, generated_images):\n",
    "        wasserstein_loss = (torch.mean(d_score_generated) - torch.mean(d_score_real)) / self.gamma\n",
    "        \n",
    "        epsilon = self.epsilon_buffer.uniform_(0, 1)\n",
    "        real_fake_mix = epsilon * generated_images + (1 - epsilon) * real_images \n",
    "        gradient_penalty = self.gradient_penalty(real_fake_mix)        \n",
    "        \n",
    "        d_regularizer_mean = torch.mean(d_score_real ** 2)\n",
    "        d_loss = -wasserstein_loss +  gradient_penalty + self.discriminator_epsilon * d_regularizer_mean\n",
    "        return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanachWGAN(nn.Module):\n",
    "    def __init__(self, gamma, noise_size=128, num_filters=128, num_generator_blocks=3, num_discriminator_blocks=4,\n",
    "                 batch_size=64, num_channels=3, discriminator_epsilon=1e-5, embedding_func=identity_embedding, \n",
    "                 embedding_size=None, discriminator_hidden_size=None, discriminator_type=\"Image\"):  \n",
    "        super(BanachWGAN, self).__init__(gamma=gamma, noise_size=noise_size, num_filters=num_filters, \n",
    "                                         num_generator_blocks=num_generator_blocks, \n",
    "                                         num_discriminator_blocks=num_discriminator_blocks, \n",
    "                                         batch_size=batch_size, num_channels=num_channels, \n",
    "                                         discriminator_epsilon=discriminator_epsilon,\n",
    "                                         embedding_size=None, discriminator_hidden_size=None, \n",
    "                                         discriminator_type=\"Image\")\n",
    "        \n",
    "        self.embedding_func = embedding_func\n",
    "        \n",
    "        if discriminator_type == \"Vector\":\n",
    "            self.noise_buffer.squeeze(-1)\n",
    "            self.noise_buffer.squeeze(-1)\n",
    "    \n",
    "    def forward_train_discriminator(self, real_images, noise=None):\n",
    "        generated_images = self.forward_predict_generator(noise)\n",
    "        real_data = self.embedding_func(real_images)\n",
    "        generated_data = self.embedding_func(generated_images)\n",
    "        \n",
    "        discriminator_score_generated = self.discriminator(generated_data)\n",
    "        discriminator_score_real = self.discriminator(real_data)\n",
    "        \n",
    "        return self.discriminator_loss(discriminator_score_real, discriminator_score_generated, \n",
    "                                       real_data, generated_data)\n",
    "        \n",
    "    def forward_predict_discriminator(self, images):\n",
    "        return self.discriminator(self.embedding_func(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricWGAN(WGAN):\n",
    "    def __init__(self, gamma, noise_size=128, num_filters=128, num_generator_blocks=3, num_discriminator_blocks=4,\n",
    "                 batch_size=64, num_channels=3, discriminator_epsilon=1e-5, embedding_func=identity_embedding, \n",
    "                 embedding_size=None, discriminator_hidden_size=None, discriminator_type=\"Image\"):  \n",
    "        super(MetricWGAN, self).__init__(gamma=gamma, noise_size=noise_size, num_filters=num_filters, \n",
    "                                         num_generator_blocks=num_generator_blocks, \n",
    "                                         num_discriminator_blocks=num_discriminator_blocks, \n",
    "                                         batch_size=batch_size, num_channels=num_channels, \n",
    "                                         discriminator_epsilon=discriminator_epsilon,\n",
    "                                         embedding_size=None, discriminator_hidden_size=None, \n",
    "                                         discriminator_type=\"Image\")\n",
    "        self.embedding_func = embedding_func\n",
    "        \n",
    "        self.noise_buffer.unsqueeze(1)\n",
    "        self.noise_buffer.repeat(2, 1, 1, 1, 1).view(2 * batch_size, 1, 1, 1)\n",
    "        self.batch_size = batch_size\n",
    "        self.pdist = nn.PairwiseDistance()\n",
    "    \n",
    "    def gradient_penalty(self, real_fake_mix):\n",
    "        sampled_data = self.embedding_func(real_fake_mix) # 2 * batch_size x embedding_size\n",
    "        sampled_scores = self.discriminator(sampled_data).view(2, self.batch_size) # 2 x batch_size\n",
    "        sampled_data = sampled_data.view(2, self.batch_size, -1) # 2 x batch_size x embedding_size\n",
    "        \n",
    "        num_dist = (sampled_scores[0] - sampled_scores[1]).abs()\n",
    "        denom_dist = self.pdist(sampled_data[0], sampled_data[1])\n",
    "        \n",
    "        return ((num_dist/denom_dist - 1)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# There is one discrepancy in this training code and the bwgan github implementation. That\n",
    "# version uses an exponential moving average of the weights during evaluation.\n",
    "#\n",
    "# One other discrepancy with bwgan is the lack of usage of warm restarts for SGD. That's mentioned in\n",
    "# the paper but I could not see in the implementation.\n",
    "#\n",
    "# The last main discrepancy is related to the model. In the bwgan code gamma is computed each batch. Here\n",
    "# we compute gamma over the dataset instead. The difference should be very minor as gamma's value across batches\n",
    "# is pretty stable. For MNIST gamma appeared to range from 29.8-30.1 from looking at a dozen gamma values.\n",
    "def gan_train(model, dset_loader, optimizers, lr_schedulers, num_updates=1e5,\n",
    "              use_cuda=False, num_discriminator=5):\n",
    "    steps_so_far = 0\n",
    "    curr_epoch = 0\n",
    "    \n",
    "    discriminator_optimizer, generator_optimizer = optimizers\n",
    "    discriminator_lr_scheduler, generator_lr_scheduler = lr_schedulers\n",
    "    \n",
    "    display_generator = False\n",
    "    \n",
    "    while True:\n",
    "        print('Epoch {} - Step {}/{}'.format(curr_epoch, steps_so_far, num_updates))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data, _ in dset_loader:\n",
    "            if steps_so_far % 1000 == 0:\n",
    "                print(steps_so_far)\n",
    "            \n",
    "            if steps_so_far >= num_updates:\n",
    "                return model\n",
    "            \n",
    "            if use_cuda:\n",
    "                data = data.cuda()\n",
    "            \n",
    "            loss = model.forward_train_discriminator(data)\n",
    "#             register_hooks(loss)\n",
    "            \n",
    "            if steps_so_far % 10 == 4:\n",
    "                print(\"Discriminator Loss: \", loss.item())\n",
    "                display_generator = True\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            discriminator_optimizer.step()\n",
    "            # zero the parameter gradients\n",
    "            discriminator_optimizer.zero_grad()\n",
    "                \n",
    "                \n",
    "            if steps_so_far % num_discriminator == num_discriminator-1:\n",
    "                # This is done because in 1 step the discriminator sees two batches of images\n",
    "                # while the generator only sees 1.\n",
    "                loss = (model.forward_train_generator() + model.forward_train_generator())/2\n",
    "                loss.backward()\n",
    "                generator_optimizer.step()\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                generator_optimizer.zero_grad()\n",
    "\n",
    "                discriminator_lr_scheduler.step()\n",
    "                generator_lr_scheduler.step()\n",
    "                if display_generator:\n",
    "                    print(\"Generator Loss: \", loss.item())\n",
    "                    display_generator = False\n",
    "                    \n",
    "                    \n",
    "            if steps_so_far % 500 == 0:\n",
    "                generated_images = model.forward_predict_generator()\n",
    "                first_image = generated_images[0, 0].cpu().detach().numpy()\n",
    "                min_val = float(np.amin(first_image))\n",
    "                max_val = float(np.amax(first_image))\n",
    "                plt.title(\"Generated image, range {} to {}\".format(round(min_val, 3), round(max_val, 3)))\n",
    "                plt.imshow(first_image)\n",
    "                plt.show()\n",
    "            \n",
    "            steps_so_far += 1\n",
    "        \n",
    "        curr_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_gamma(dset_loader):\n",
    "    num_images = len(dset_loader.dataset)\n",
    "    gamma = 0.0\n",
    "    \n",
    "    for data, _ in dset_loader:\n",
    "        batch_size = data.size()[0]\n",
    "        gamma += data.cuda().view(batch_size, -1).norm(2, dim=1).sum().item() / num_images\n",
    "    \n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_graph(root, callback):\n",
    "    queue = [root]\n",
    "    seen = set()\n",
    "    while queue:\n",
    "        fn = queue.pop()\n",
    "        if fn in seen:\n",
    "            continue\n",
    "        seen.add(fn)\n",
    "        for next_fn, _ in fn.next_functions:\n",
    "            if next_fn is not None:\n",
    "                queue.append(next_fn)\n",
    "        callback(fn)\n",
    "\n",
    "def register_hooks(var):\n",
    "    def is_bad_grad(grad_output):\n",
    "        if grad_output is None:\n",
    "            return False\n",
    "        \n",
    "        grad_output = grad_output.data\n",
    "        return grad_output.ne(grad_output).any() or grad_output.gt(1e4).any()\n",
    "    \n",
    "    def hook_cb(fn):\n",
    "        def register_grad(grad_input, grad_output):\n",
    "            for grad in grad_output:\n",
    "                if is_bad_grad(grad):\n",
    "                    print(fn)\n",
    "#                     raise ValueError(\"Hi\")\n",
    "        fn.register_hook(register_grad)\n",
    "    iter_graph(var.grad_fn, hook_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_size = 128\n",
    "batch_size = 1\n",
    "use_cuda = True\n",
    "base_lr = 2e-4\n",
    "num_updates = int(1e2)\n",
    "num_discriminator = 5\n",
    "num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(name, train=True):\n",
    "    assert name in [\"mnist\", \"cifar\", \"celeba\"]\n",
    "    transform = transforms.Compose([transforms.Resize(32),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "    if name == \"mnist\":\n",
    "        return datasets.MNIST(\"mnist\", train=train, download=True, transform=transform)\n",
    "    if name == \"cifar\":\n",
    "        return datasets.CIFAR10(\"cifar\", train=train, transform=transform, download=True)\n",
    "    if name == \"celeba\":\n",
    "        if train == True:\n",
    "            dset_str = \"train\"\n",
    "        else:\n",
    "            dset_str = \"test\"\n",
    "        with open(\"celeba_64_bgr_-1_to_1_%s.pkl\" % dset_str, \"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = get_data(\"cifar\")\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                                   num_workers=4, pin_memory=True, drop_last=True)\n",
    "gamma = compute_gamma(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Step 0/100\n",
      "----------\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Loss:  24.17747688293457\n",
      "Generator Loss:  1.4177587032318115\n",
      "Discriminator Loss:  283.9795837402344\n",
      "Generator Loss:  251.44830322265625\n",
      "Discriminator Loss:  33811.546875\n",
      "Generator Loss:  4903.61328125\n",
      "Discriminator Loss:  18311068.0\n",
      "Generator Loss:  48326.1953125\n",
      "Discriminator Loss:  2849058048.0\n",
      "Generator Loss:  394881.375\n",
      "Discriminator Loss:  5204018688.0\n",
      "Generator Loss:  1922231.5\n",
      "Discriminator Loss:  332722896896.0\n",
      "Generator Loss:  8115658.5\n",
      "Discriminator Loss:  -10302812.0\n",
      "Generator Loss:  10590965.0\n",
      "Discriminator Loss:  -12703802.0\n",
      "Generator Loss:  13210098.0\n",
      "Discriminator Loss:  3916660998144.0\n",
      "Generator Loss:  19363862.0\n",
      "3.806027412414551\n"
     ]
    }
   ],
   "source": [
    "model = WGAN(gamma=gamma, noise_size=noise_size, batch_size=batch_size, num_channels=num_channels)\n",
    "# model.train()\n",
    "# y = torch.ones(1,128)\n",
    "# output1 = model.forward_predict_generator(y)\n",
    "# # z = torch.ones(1, 3, 32, 32)\n",
    "# # output2 = model.forward_predict_discriminator(z)\n",
    "\n",
    "# print(output1)\n",
    "# print(output1.size())\n",
    "\n",
    "# print(output2)\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    model.discriminator = nn.DataParallel(model.discriminator)\n",
    "    model.generator = nn.DataParallel(model.generator)\n",
    "\n",
    "discriminator_optimizer = optim.Adam(model.discriminator.parameters(), betas=(0, 0.9), lr=base_lr)\n",
    "generator_optimizer = optim.Adam(model.generator.parameters(), betas=(0, 0.9), lr=base_lr)\n",
    "discriminator_lr_scheduler = optim.lr_scheduler.LambdaLR(discriminator_optimizer, lambda step: max(0, (1 - step/num_updates)))\n",
    "generator_lr_scheduler = optim.lr_scheduler.LambdaLR(generator_optimizer, lambda step: max(0, (1 - step/num_updates)))\n",
    "optimizers = discriminator_optimizer, generator_optimizer\n",
    "lr_schedulers = discriminator_lr_scheduler, generator_lr_scheduler\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "model.train()\n",
    "model = gan_train(model, train_dataloader, optimizers, lr_schedulers, num_updates=num_updates, \n",
    "                  use_cuda=use_cuda, num_discriminator=num_discriminator)\n",
    "print(time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
